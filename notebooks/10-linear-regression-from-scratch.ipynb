{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a329270d-2578-4d96-8800-28cce4bdbbb7",
   "metadata": {},
   "source": [
    "# Linear regression from scratch\n",
    "\n",
    "In this notebook, I want to show you some \"from scratch\" linear regression examples. The purpose is to better understand a couple of ways we can train a linear regression model (said differently: how we can learn the weights for a linear regression model). In a later notebook, I'll show you how to use Pandas and Scikit-learn.\n",
    "\n",
    "I'm importing housing price data from [housing-all.csv](https://u.pcloud.link/publink/show?code=XZg96Y5Z8xq8LWJ7URSeFTOzymFjGkN5OSaV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "466b8359-3c6d-4a0f-9b2f-07cf97299a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.        , 0.68117409, 0.09458023, ..., 0.05456992, 0.14109521,\n",
       "         0.24584488],\n",
       "        [1.        , 0.60526316, 0.13496281, ..., 0.02281454, 0.05525407,\n",
       "         0.31911284],\n",
       "        [1.        , 0.65587045, 0.16259299, ..., 0.06185711, 0.12613057,\n",
       "         0.22874167],\n",
       "        ...,\n",
       "        [1.        , 0.31882591, 0.65037194, ..., 0.02043219, 0.03946719,\n",
       "         0.34276079],\n",
       "        [1.        , 0.63259109, 0.16259299, ..., 0.10686959, 0.15293537,\n",
       "         0.13865326],\n",
       "        [1.        , 0.60728745, 0.17321998, ..., 0.01014602, 0.02795593,\n",
       "         0.10610888]], shape=(16346, 9)),\n",
       " array([240600., 458300., 258700., ..., 204800., 185000., 225000.],\n",
       "       shape=(16346,)))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "import math\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "with open('../data/housing-all.csv', 'r') as file:\n",
    "    columns = ['intercept'] + file.readline().strip().split(',')\n",
    "    for line in file:\n",
    "        row = [float(value) for value in line.strip().split(',')]\n",
    "        if len(row) > 0:\n",
    "            xs.append([1] + row[:-1]) # All the features go into a new row in xs, plus 1 to serve as the intercept.\n",
    "            ys.append(row[-1]) # The dependent variable (last column) goes into ys.\n",
    "\n",
    "# Split data into training and dev.\n",
    "trainDevThreshold = int(0.8*len(xs))\n",
    "trainXs = np.array(xs[:trainDevThreshold]) # 80% goes to training, 20% to dev.\n",
    "trainYs = np.array(ys[:trainDevThreshold])\n",
    "\n",
    "devXs = np.array(xs[trainDevThreshold:])\n",
    "devYs = np.array(ys[trainDevThreshold:])\n",
    "\n",
    "def minMaxScale(values, min, max):\n",
    "    if min == max:\n",
    "        return\n",
    "    for i in range(len(values)):\n",
    "        values[i] = (values[i] - min)/(max - min)\n",
    "\n",
    "# Scale features using trianing data. We'll just use min-max scaling.\n",
    "minMaxes = [( min(trainXs[:,col]), max(trainXs[:,col])) for col in range(len(trainXs[0]))]\n",
    "for col,minMax in enumerate(minMaxes):\n",
    "    colMin, colMax = minMax\n",
    "    minMaxScale(trainXs[:,col], colMin, colMax)\n",
    "    minMaxScale(devXs[:,col], colMin, colMax)\n",
    "\n",
    "trainXs, trainYs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "de93ea59-a9cc-4225-866a-54f4ee156411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.], shape=(16346,))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainXs[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e034efe-be41-4b21-8a6c-da717b604092",
   "metadata": {},
   "source": [
    "## Ordinary Least Squares\n",
    "\n",
    "This is one of several least squares approaches. It is closed form, meaning we can use a formula of basic operations to manipulate the data to arrive at the final weights that minimize error, as opposed to an interative approach where we continually refine weights until we reach an error we're comfortable with (we'll look at an example of that next!).\n",
    "\n",
    "The formula is:\n",
    "\n",
    "$$\\beta = \\left(X^TX\\right)^{-1} X^Ty$$\n",
    "\n",
    "where $X$ is the feature *matrix* (a 2D array) where rows are observations and columns are features, and $y$ the vector (a 1D array) of true values for each of the observations. The linear algebra operations we see left to right are *transpose* ($X^T$), which is necessary for the next operation, *matrix multiplication*, where we are multiplying $X$ by itself. Next, we take the *inverse* ($X^{-1}$) of the result (this finds another matrix that, when multiplied with $X$ yields an identity matrix, which is the equivalent of the number \"1\" in matrix land). We multiply that result with the transpose of $X$ again, then finally multiply the resulting matrix with the vector $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "564b488d-6fad-4b55-afe2-e6edcc017ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  369914.73252504,  -426310.32627907,  -404218.66258238,\n",
       "          57873.48435623,  -331098.74881244,   779856.23326378,\n",
       "       -1312274.72168028,   223637.35618937,   583329.64477493])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The \"@\" are used by Numpy for matrix/vector multiplication.\n",
    "weights = (linalg.inv(trainXs.T @ trainXs) @ trainXs.T) @ trainYs\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "de2d6321-5890-44e6-a7f8-1c1013b778a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept           :     369914.7325\n",
      "longitude           :    -426310.3263\n",
      "latitude            :    -404218.6626\n",
      "housing_median_age  :      57873.4844\n",
      "total_rooms         :    -331098.7488\n",
      "total_bedrooms      :     779856.2333\n",
      "population          :   -1312274.7217\n",
      "households          :     223637.3562\n",
      "median_income       :     583329.6448\n"
     ]
    }
   ],
   "source": [
    "for feature,weight in zip(columns, weights):\n",
    "    print(f'{feature:<20}: {weight:>15.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e729d7e2-f1cf-442b-a738-b1203372cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error: 68881.30146276834\n"
     ]
    }
   ],
   "source": [
    "# Evaluate -- how well do we predict the dev set?\n",
    "errors = devYs - devXs @ weights\n",
    "print('Root mean squared error:', \n",
    "    math.sqrt(sum([error**2 for error in errors])/len(devYs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c2fd51ee-e2cc-4c49-8c89-517488d1e96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.21963563, 0.60467588, 0.39215686, 0.0628974 ,\n",
       "       0.05276226, 0.0226744 , 0.05048512, 0.4661315 ])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devXs[-1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "186eb125-3d43-48f2-812b-8b8481e36b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328321.36984791735"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*369914.7325 + 0.21963563*-426310.3263 + 0.60467588*-404218.6626 + 0.39215686*57873.4844 + 0.0628974*-331098.7488 + \\\n",
    "0.05276226*779856.2333 + 0.0226744*-1312274.7217 + 0.05048512*223637.3562 + 0.4661315*583329.6448\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e113c95-7390-467b-8874-9478571a3c80",
   "metadata": {},
   "source": [
    "## Stocastic gradient decent\n",
    "\n",
    "This is an iterative method that performs a number of *epochs*. In one epoch, each of the observations in the training set are iterated over. On each iteration, the weights are adjusted based on the difference between the prediction using the most recent weights and the true dependent varaible (y) for the given observation ($h$ in the example below, which let's imagine is short for *hypothesis*), scaled by both $alpha$ (the learning rate) and the feature value that corresponds with the weight being updated.\n",
    "\n",
    "In the example below, I've set the learning rate to 0.01 and the number of epochs to 50; these can both be tweaked. We might also shuffle the observations since that might have an effect on how much weights are adjusted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b071966d-ca2a-4022-99bf-aa8fac94312d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 171984, -176659, -179908,   72044,      14,   59933,       7,\n",
       "         10409,  571664])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weights + intercept to 1.\n",
    "weights = np.array([1]*(len(columns)-1)) # -1 because y is included in the column names.\n",
    "# This is our learning rate -- how much to adjust weights by relative to error (smaller values = slower, but more accurate)\n",
    "alpha = 0.001\n",
    "\n",
    "print('Epoch ', end='')\n",
    "for epoch in range(50):\n",
    "    print(f'{epoch},', end='')\n",
    "    for row, y in zip(trainXs, trainYs):\n",
    "        h = sum([x*weight for (x,weight) in zip(row, weights)])\n",
    "\n",
    "        # Update each of the weights.\n",
    "        for i in range(len(weights)):\n",
    "            weights[i] = weights[i] - alpha*(h - y)*row[i]\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d3c70bfb-692a-46aa-a848-4e08275a8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept           :     171984.0000\n",
      "longitude           :    -176659.0000\n",
      "latitude            :    -179908.0000\n",
      "housing_median_age  :      72044.0000\n",
      "total_rooms         :         14.0000\n",
      "total_bedrooms      :      59933.0000\n",
      "population          :          7.0000\n",
      "households          :      10409.0000\n",
      "median_income       :     571664.0000\n"
     ]
    }
   ],
   "source": [
    "for feature,weight in zip(columns, weights):\n",
    "    print(f'{feature:<20}: {weight:>15.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "04516817-b8a4-48eb-b700-4b59e7a10094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error: 74858.75824406656\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# We could calculated RMSE the same as above, but let's try it down here without matrix multiplication.\n",
    "errors = []\n",
    "for devX, devY in zip(devXs, devYs):\n",
    "    # Calculates the error between each predicted dev Y and the actual dev Y\n",
    "    errors.append(sum([x*weight for (x,weight) in zip(devX,weights)]) - devY)\n",
    "\n",
    "sumSquaredErrors = sum([error**2 for error in errors])\n",
    "\n",
    "print('Root mean squared error:', \n",
    "    math.sqrt(sumSquaredErrors/len(devXs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60a8b3d-eb53-4f7a-93b4-942ca89379ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
